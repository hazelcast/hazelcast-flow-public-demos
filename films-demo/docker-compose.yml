services:
   hazelcast-flow:
      image: "docker.io/hazelcast/hazelcast-flow:5.5.0"
      environment:
         MC_LICENSE: "${MC_LICENSE}"
         JAVA_OPTS: >-
            -XX:MaxRAMPercentage=50
            -XX:InitialRAMPercentage=50
         OPTIONS: >-
            --flow.analytics.persistRemoteCallResponses=true
            --flow.analytics.persistResults=true
            --flow.workspace.config-file=/opt/service/workspace/workspace.conf
            --flow.db.database=flow
            --flow.db.username=flow
            --flow.db.password=changeme
            --flow.db.host=pg-pagila
            --flow.config.custom.managementCenterUrl=http://localhost:8080
            --flow.hazelcast.configYamlPath=/opt/hazelcast/config_ext/hazelcast.yml
      expose:
         - 9021
      ports:
         - "9021:9021"
      healthcheck:
         test: curl --fail http://localhost:9021/api/actuator/health || exit 1
         interval: 30s
         timeout: 5s
         retries: 3
      volumes:
         - .:/opt/service/workspace
         - type: bind
           source: ./hazelcast.yml
           target: /opt/hazelcast/config_ext/hazelcast.yml
      depends_on:
         - pg-pagila
      deploy:
         restart_policy:
            condition: on-failure
         resources:
            limits:
               memory: 2gb

   management-center:
      image: "docker.io/hazelcast/management-center-flow:5.6.0"
      ports:
        - "8080:8080"
      healthcheck:
        test: curl --fail http://localhost:8080/health || exit 1
        interval: 30s
        timeout: 5s
        retries: 3
      environment:
        - JAVA_OPTS=-Dhazelcast.mc.flow.addresses=http://localhost:9021 -Dhazelcast.mc.flow.internalAddress=http://hazelcast-flow:9021
        - MC_DEFAULT_CLUSTER=flow
        - MC_DEFAULT_CLUSTER_MEMBERS=hazelcast-flow:5701
        - MC_LICENSE=${MC_LICENSE}
        - MC_INIT_CMD=./bin/mc-conf.sh security reset && ./bin/mc-conf.sh dev-mode configure

   pg-pagila:
      build:
         context: "docker/pagila-database"
         dockerfile: "Dockerfile"
      expose:
         - 5432
      ports:
         - "35432:5432"
      environment:
         POSTGRES_DB: pagila
         POSTGRES_USER: postgres
         POSTGRES_PASSWORD: admin

   films-api:
      build:
         context: "."
         dockerfile: "Dockerfile"
      expose:
         - 80
      ports:
         - "9981:80"
      environment:
         OPTIONS: >-
            --spring.kafka.bootstrap-servers=kafka:19092
      deploy:
         restart_policy:
            condition: on-failure
         resources:
            limits:
               memory: 300mb

   kafka:
      image: "docker.io/apache/kafka:3.7.0"
      hostname: kafka
      container_name: kafka
      environment:
         KAFKA_NODE_ID: 1
         KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
         KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT_HOST://localhost:9092,PLAINTEXT://kafka:19092'
         KAFKA_PROCESS_ROLES: 'broker,controller'
         KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
         KAFKA_LISTENERS: 'CONTROLLER://:29093,PLAINTEXT_HOST://0.0.0.0:9092,PLAINTEXT://0.0.0.0:19092'
         KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
         KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
         CLUSTER_ID: '4L6g3nShT-eMCtK--X86sw'
         KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
         KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
         KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
         KAFKA_LOG_RETENTION_MS: 60000
         KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 5000
      ports:
         - "19092:19092"

volumes:
   postgres_data:
